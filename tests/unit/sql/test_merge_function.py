# SPDX-FileCopyrightText: 2024-present Richard Dahl <richard@dahl.us>
#
# SPDX-License-Identifier: MIT

"""
Integration tests for the TableMergeFunction emitter.

These tests verify that the merge function SQL generated by the
TableMergeFunction emitter works correctly when executed in a
PostgreSQL database.
"""

import pytest
import json
from sqlalchemy import Table, Column, MetaData, String, Integer, Text, create_engine, UniqueConstraint
from sqlalchemy.sql import text
from sqlalchemy.exc import ProgrammingError

from uno.sql.emitters import TableMergeFunction
from uno.database.config import ConnectionConfig
from uno.settings import uno_settings

# Skip these tests by default
pytestmark = pytest.mark.skip(
    reason="Requires database connection. These are integration tests that require a database."
)

@pytest.fixture
def connection_config():
    """Create a test database connection configuration."""
    return ConnectionConfig(
        db_name=uno_settings.DB_NAME,
        db_schema=uno_settings.DB_SCHEMA,
        db_user_pw=uno_settings.DB_USER_PW,
        db_driver="postgresql+psycopg2"
    )

@pytest.fixture
def db_engine(connection_config):
    """Create a test database engine."""
    engine = create_engine(connection_config.connection_url)
    # Verify connection
    try:
        with engine.connect() as conn:
            conn.execute(text("SELECT 1"))
    except Exception as e:
        pytest.skip(f"Database connection failed: {e}")
    
    # Return the engine
    yield engine

@pytest.fixture
def test_table(db_engine):
    """Create a sample table for testing the merge function."""
    metadata = MetaData()
    schema = uno_settings.DB_SCHEMA
    
    # Define the test table with primary key and unique constraints
    test_table = Table(
        "test_merge_users",
        metadata,
        Column("id", String(26), primary_key=True),
        Column("email", String(255)),
        Column("username", String(100)),
        Column("name", String(255)),
        Column("age", Integer),
        UniqueConstraint("email", name="test_merge_users_email_key"),
        UniqueConstraint("username", name="test_merge_users_username_key"),
        schema=schema
    )
    
    # Create the table
    metadata.create_all(db_engine)
    
    # Return the table object
    yield test_table
    
    # Drop the table after tests
    try:
        # First drop the merge function if it exists
        with db_engine.connect() as conn:
            conn.execute(text(f"DROP FUNCTION IF EXISTS {schema}.merge_test_merge_users_record(jsonb)"))
            conn.commit()
        
        # Then drop the table
        metadata.drop_all(db_engine)
    except Exception as e:
        print(f"Error during cleanup: {e}")


class TestMergeFunction:
    """Integration tests for the TableMergeFunction."""
    
    def test_merge_function_creation(self, db_engine, test_table, connection_config):
        """Test creating the merge function."""
        # Create the emitter
        emitter = TableMergeFunction(
            table=test_table,
            connection_config=connection_config
        )
        
        # Generate the SQL
        statements = emitter.generate_sql()
        assert len(statements) == 1
        
        # Execute the SQL to create the function
        with db_engine.connect() as conn:
            try:
                conn.execute(text(statements[0].sql))
                conn.commit()
            except Exception as e:
                pytest.fail(f"Failed to create merge function: {e}")

    def test_merge_function_operations(self, db_engine, test_table, connection_config):
        """Test the merge function with different operations."""
        schema = connection_config.db_schema
        
        # Create the merge function
        emitter = TableMergeFunction(table=test_table, connection_config=connection_config)
        with db_engine.connect() as conn:
            conn.execute(text(emitter.generate_sql()[0].sql))
            conn.commit()
        
        # Tests with different operations
        with db_engine.connect() as conn:
            # Test 1: Insert a new record with primary key
            data = {
                "id": "user123",
                "email": "test@example.com",
                "username": "testuser",
                "name": "Test User",
                "age": 30
            }
            result = conn.execute(
                text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                {"data": json.dumps(data)}
            ).scalar()
            result_dict = json.loads(result)
            assert result_dict["_action"] == "inserted"
            assert result_dict["id"] == "user123"
            assert result_dict["name"] == "Test User"
            
            # Test 2: Update the record
            updated_data = {
                "id": "user123",
                "name": "Updated Name",
                "age": 31
            }
            result = conn.execute(
                text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                {"data": json.dumps(updated_data)}
            ).scalar()
            result_dict = json.loads(result)
            assert result_dict["_action"] == "updated"
            assert result_dict["name"] == "Updated Name"
            assert result_dict["age"] == 31
            assert result_dict["email"] == "test@example.com"  # Original data preserved
            
            # Test 3: Select with no changes
            same_data = {
                "id": "user123",
                "name": "Updated Name"  # No change from previous
            }
            result = conn.execute(
                text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                {"data": json.dumps(same_data)}
            ).scalar()
            result_dict = json.loads(result)
            assert result_dict["_action"] == "selected"
            
            # Test 4: Insert using unique constraint instead of PK
            user_by_email = {
                "email": "another@example.com",
                "username": "another",
                "name": "Another User",
                "age": 25
            }
            result = conn.execute(
                text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                {"data": json.dumps(user_by_email)}
            ).scalar()
            result_dict = json.loads(result)
            assert result_dict["_action"] == "inserted"
            assert result_dict["email"] == "another@example.com"
            
            # Test 5: Update using unique constraint
            update_by_email = {
                "email": "another@example.com",
                "name": "Updated Another"
            }
            result = conn.execute(
                text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                {"data": json.dumps(update_by_email)}
            ).scalar()
            result_dict = json.loads(result)
            assert result_dict["_action"] == "updated"
            assert result_dict["name"] == "Updated Another"
            
            # Test 6: Attempt with insufficient key data
            insufficient_data = {
                "name": "Insufficient Data",
                "age": 40
            }
            try:
                conn.execute(
                    text(f"SELECT {schema}.merge_test_merge_users_record(:data)"),
                    {"data": json.dumps(insufficient_data)}
                )
                pytest.fail("Expected exception was not raised")
            except Exception as e:
                # Should fail because there's no primary key or unique constraint
                assert "No primary keys or unique constraints found" in str(e)